{"expireTime":9007200904342771000,"key":"transformer-remark-markdown-html-5a586db3831961ce7f2fe95334e84ffb--","val":"<h1>Frequency and the fast Fourier transform</h1>\n<blockquote>\n<p>If you want to find the secrets of the universe, think in terms of energy,\nfrequency and vibration.</p>\n<p>— Nikola Tesla</p>\n</blockquote>\n<p><em>This chapter was written in collaboration with SW's father, PW van der Walt.</em></p>\n<h2>Introducing frequency</h2>\n<p>We'll start by setting up some plotting styles and importing the usual\nsuspects:</p>\n<pre><code class=\"language-python\"># Make plots appear inline, set custom plotting style\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use('style/elegant.mplstyle')\n</code></pre>\n<pre><code class=\"language-python\">import numpy as np\n</code></pre>\n<p>The discrete<sup id=\"fnref-discrete\"><a href=\"#fn-discrete\" class=\"footnote-ref\">discrete</a></sup> Fourier transform (DFT) is a mathematical technique\nto convert temporal or spatial data into <em>frequency domain</em> data.\n<em>Frequency</em> is a familiar concept, due to its colloquial occurrence in\nthe English language: the lowest notes your headphones can rumble out\nare around 20 Hertz, whereas middle C on a piano lies around 261.6\nHertz. Hertz (Hz), or oscillations per second, in this case literally\nrefers to the number of times per second at which the membrane inside\nthe headphone moves to-and-fro. That, in turn, creates compressed\npulses of air which, upon arrival at your eardrum, induces a vibration\nat the same frequency. So, if you take a simple periodic function, $\\sin(10 \\times 2 \\pi t)$, you can view it as a wave:</p>\n<pre><code class=\"language-python\">f = 10  # Frequency, in cycles per second, or Hertz\nf_s = 100  # Sampling rate, or number of measurements per second\n\nt = np.linspace(0, 2, 2 * f_s, endpoint=False)\nx = np.sin(f * 2 * np.pi * t)\n\nfig, ax = plt.subplots()\nax.plot(t, x)\nax.set_xlabel('Time [s]')\nax.set_ylabel('Signal amplitude');\n</code></pre>\n<!-- caption text=\"A simple periodic function in time\" -->\n<p>Or you can equivalently think of it as a repeating signal of\n<em>frequency</em> 10 Hertz (it repeats once every $1/10$ seconds—a length of\ntime we call its <em>period</em>). Although we naturally associate frequency\nwith time, it can equally well be applied to space. E.g., a\nphoto of a textile patterns exhibits high <em>spatial frequency</em>, whereas\nthe sky or other smooth objects have low spatial frequency.</p>\n<p>Let us now examine our sinusoid through application of the discrete Fourier\ntransform:</p>\n<pre><code class=\"language-python\">from scipy import fftpack\n\nX = fftpack.fft(x)\nfreqs = fftpack.fftfreq(len(x)) * f_s\n\nfig, ax = plt.subplots()\n\nax.stem(freqs, np.abs(X))\nax.set_xlabel('Frequency in Hertz [Hz]')\nax.set_ylabel('Frequency Domain (Spectrum) Magnitude')\nax.set_xlim(-f_s / 2, f_s / 2)\nax.set_ylim(-5, 110)\n</code></pre>\n<!-- caption text=\"Frequencies that make up our periodic signal above\" -->\n<p>We see that the output of the FFT is a one-dimensional array of the\nsame shape as the input, containing complex values. All values are\nzero, except for two entries. Traditionally, we visualize the\nmagnitude of the result as a <em>stem plot</em>, in which the height of each\nstem corresponds to the underlying value.</p>\n<p>(We explain why you see positive and negative frequencies later on\nin the sidebox titled \"Discrete Fourier transforms\". You may also\nrefer to that section for a more in-depth overview of the underlying\nmathematics.)</p>\n<p>The Fourier transform takes us from the <em>time</em> to the <em>frequency</em>\ndomain, and this turns out to have a massive number of applications.\nThe <em>fast Fourier transform</em> is an algorithm for computing the\ndiscrete Fourier transform; it achieves its high speed by storing and\nre-using results of computations as it progresses.</p>\n<p>In this chapter, we examine a few applications of the discrete Fourier\ntransform to demonstrate that the FFT can be applied to\nmultidimensional data (not just 1D measurements) to achieve a variety\nof goals.</p>\n<h2>Illustration: a birdsong spectrogram</h2>\n<p>Let's start with one of the most common applications, converting a sound signal (consisting of variations of air pressure over time) to a <em>spectrogram</em>.\nYou might have seen spectrograms on your music player's equalizer view, or even on an old-school stereo.</p>\n<p><img src=\"../images/sergey_gerasimuk_numark-eq-2600-IMG_0236.jpg\" alt=\"The Numark EQ2600 Stereo Equalizer; image used with permission from the author, Sergey Gerasimuk. Source: http://sgerasimuk.blogspot.com/2014/06/numark-eq-2600-10-band-stereo-graphic.html\"></p>\n<p>Listen to the following snippet of nightingale birdsong (released under CC BY 4.0 at\n<a href=\"http://www.orangefreesounds.com/nightingale-sound/\">http://www.orangefreesounds.com/nightingale-sound/</a>):</p>\n<pre><code class=\"language-python\">from IPython.display import Audio\nAudio('data/nightingale.wav')\n</code></pre>\n<p>If you are reading the paper version of this book, you'll have to use\nyour imagination! It goes something like this:\nchee-chee-woorrrr-hee-hee cheet-wheet-hoorrr-chi\nrrr-whi-wheo-wheo-wheo-wheo-wheo-wheo.</p>\n<p>Since we realise that not everyone is fluent in bird-speak, perhaps\nit's best if we visualize the measurements—better known as \"the\nsignal\"—instead.</p>\n<p>We load the audio file, which gives us\nthe sampling rate (number of measurements per second) as well as audio\ndata as an <code>(N, 2)</code> array—two columns because this is a stereo\nrecording.</p>\n<pre><code class=\"language-python\">from scipy.io import wavfile\n\nrate, audio = wavfile.read('data/nightingale.wav')\n</code></pre>\n<p>We convert to mono by averaging the left and right channels.</p>\n<pre><code class=\"language-python\">audio = np.mean(audio, axis=1)\n</code></pre>\n<p>Then, calculate the length of the snippet and plot the audio.</p>\n<pre><code class=\"language-python\">N = audio.shape[0]\nL = N / rate\n\nprint(f'Audio length: {L:.2f} seconds')\n\nf, ax = plt.subplots()\nax.plot(np.arange(N) / rate, audio)\nax.set_xlabel('Time [s]')\nax.set_ylabel('Amplitude [unknown]');\n</code></pre>\n<!-- caption text=\"Audio waveform plot of birdsong\" -->\n<p>Well, that's not very satisfying, is it? If I sent this voltage to a\nspeaker, I might hear a bird chirping, but I can't very well imagine\nhow it would sound like in my head. Is there a better way of <em>seeing</em>\nwhat is going on?</p>\n<p>There is, and it is called the discrete Fourier transform, where\ndiscrete refers to the recording consisting of time-spaced sound\nmeasurements, in contrast to a continual recording as, e.g., on\nmagnetic tape (remember casettes?). The discrete Fourier\ntransform is often computed using the <em>fast Fourier transform</em> (FFT)\nalgorithm, a name informally used to refer to the DFT itself. The\nDFT tells us which frequencies or \"notes\" to expect in our signal.</p>\n<p>Of course, a bird sings many notes throughout the song, so we'd also\nlike to know <em>when</em> each note occurs. The Fourier transform takes a\nsignal in the time domain (i.e., a set of measurements over time) and\nturns it into a spectrum—a set of frequencies with corresponding\n(complex<sup id=\"fnref-complex\"><a href=\"#fn-complex\" class=\"footnote-ref\">complex</a></sup>) values. The spectrum does not contain any information about\ntime! <sup id=\"fnref-time\"><a href=\"#fn-time\" class=\"footnote-ref\">time</a></sup></p>\n<p>So, to find both the frequencies and the time at which they were sung,\nwe'll need to be somewhat clever. Our strategy is as follows:\ntake the audio signal, split it into small, overlapping slices, and\napply the Fourier transform to each (a technique known as the Short\nTime Fourier Transform).</p>\n<p>We'll split the signal into slices of 1024 samples—that's about 0.02\nseconds of audio. Why we choose 1024 and not 1000 we'll explain in a\nsecond when we examine performance. The slices will overlap by 100\nsamples as shown here:</p>\n<p><img src=\"../figures/generated/sliding_window.png\" alt=\"A sliding window operation\"></p>\n<p>Start by chopping up the signal into slices of 1024 samples, each\nslice overlapping the previous by 100 samples. The resulting <code>slices</code>\nobject contains one slice per row.</p>\n<pre><code class=\"language-python\">from skimage import util\n\nM = 1024\n\nslices = util.view_as_windows(audio, window_shape=(M,), step=100)\nprint(f'Audio shape: {audio.shape}, Sliced audio shape: {slices.shape}')\n</code></pre>\n<p>Generate a windowing function (see the section on windowing for a\ndiscussion of the underlying assumptions and interpretations of each)\nand multiply it with the signal:</p>\n<pre><code class=\"language-python\">win = np.hanning(M + 1)[:-1]\nslices = slices * win\n</code></pre>\n<p>It's more convenient to have one slice per column, so we take the transpose:</p>\n<pre><code class=\"language-python\">slices = slices.T\nprint('Shape of `slices`:', slices.shape)\n</code></pre>\n<p>For each slice, calculate the discrete Fourier transform. The DFT\nreturns both positive and negative frequencies (more on that in\n\"Frequencies and their ordering\"), so we slice out the positive M / 2\nfrequencies for now.</p>\n<pre><code class=\"language-python\">spectrum = np.fft.fft(slices, axis=0)[:M // 2 + 1:-1]\nspectrum = np.abs(spectrum)\n</code></pre>\n<p>(As a quick aside, you'll note that we use <code>scipy.fftpack.fft</code> and\n<code>np.fft</code> interchangeably. NumPy provides basic FFT functionality,\nwhich SciPy extends further, but both include an <code>fft</code> function, based\non the Fortran FFTPACK.)</p>\n<p>The spectrum can contain both very large and very small values.\nTaking the log compresses the range significantly.</p>\n<p>Here we do a log plot of the ratio of the signal divided by the maximum signal.\nThe specific unit used for the ratio is the decibel, $20\nlog_{10}\\left(\\mathrm{amplitude ratio}\\right)$.</p>\n<pre><code class=\"language-python\">f, ax = plt.subplots(figsize=(4.8, 2.4))\n\nS = np.abs(spectrum)\nS = 20 * np.log10(S / np.max(S))\n\nax.imshow(S, origin='lower', cmap='viridis',\n          extent=(0, L, 0, rate / 2 / 1000))\nax.axis('tight')\nax.set_ylabel('Frequency [kHz]')\nax.set_xlabel('Time [s]');\n</code></pre>\n<!-- caption text=\"Birdsong spectrogram\" -->\n<p>Much better! We can now see the frequencies vary over time, and it\ncorresponds to the way the audio sounds. See if you can match my\nearlier description: chee-chee-woorrrr-hee-hee cheet-wheet-hoorrr-chi\nrrr-whi-wheo-wheo-wheo-wheo-wheo-wheo (I didn't transcribe the section\nfrom 3 to 5 seconds—that's another bird).</p>\n<p>SciPy already includes an implementation of this\nprocedure as <code>scipy.signal.spectrogram</code>, which can be invoked as\nfollows:</p>\n<pre><code class=\"language-python\">from scipy import signal\n\nfreqs, times, Sx = signal.spectrogram(audio, fs=rate, window='hanning',\n                                      nperseg=1024, noverlap=M - 100,\n                                      detrend=False, scaling='spectrum')\n\nf, ax = plt.subplots(figsize=(4.8, 2.4))\nax.pcolormesh(times, freqs / 1000, 10 * np.log10(Sx), cmap='viridis')\nax.set_ylabel('Frequency [kHz]')\nax.set_xlabel('Time [s]');\n</code></pre>\n<!-- caption text=\"SciPy built-in rendition of birdsong spectrogram\" -->\n<p>The only differences are that SciPy returns the spectrum magnitude\nsquared (which turns measured voltage into measured energy), and\nmultiplies it by some normalization factors<sup id=\"fnref-scaling\"><a href=\"#fn-scaling\" class=\"footnote-ref\">scaling</a></sup>.</p>\n<h2>History</h2>\n<p>Tracing the exact origins of the Fourier transform is tricky. Some\nrelated procedures go as far back as Babylonian times, but it was the\nhot topics of calculating asteroid orbits and solving the heat (flow)\nequation that led to several breakthroughs in the early 1800s. Whom\nexactly among Clairaut, Lagrange, Euler, Gauss and D'Alembert we\nshould thank is not exactly clear, but Gauss was the first to describe\nthe fast Fourier transform (an algorithm for computing the discrete\nFourier transform, popularized by Cooley and Tukey in 1965). Joseph\nFourier, after whom the transform is named, first claimed that\n<em>arbitrary</em> periodic <sup id=\"fnref-periodic\"><a href=\"#fn-periodic\" class=\"footnote-ref\">periodic</a></sup> functions can be expressed as a sum of\ntrigonometric functions.</p>\n<h2>Implementation</h2>\n<p>The discrete Fourier transform functionality in SciPy lives in the\n`scipy.fftpack<code></code> module. Among other things, it provides the\nfollowing DFT-related functionality:</p>\n<ul>\n<li><code>fft</code>, <code>fft2</code>, <code>fftn</code>: Compute the discrete Fourier transform using</li>\n<li>the Fast Fourier Transform algorithm in 1, 2, or <code>n</code> dim</li>\n<li><code>ifft</code>, <code>ifft2</code>, <code>ifftn</code>: Compute the inverse of the DFT</li>\n<li><code>dct</code>, <code>idct</code>, <code>dst</code>, <code>idst</code>: Compute the cosine and sine transforms, and their inverses.</li>\n<li><code>fftshift</code>, <code>ifftshift</code>: Shift the zero-frequency component to the c</li>\n<li><code>fftfreq</code>: Return the discrete Fourier transform sample frequencies.</li>\n<li><code>rfft</code>: Compute the DFT of a real sequence, exploiting the symmetry of the resulting spectrum for increased performance. Also used by <code>fft</code> internally when applicable.</li>\n</ul>\n<p>This is complemented by the following functions in NumPy:</p>\n<ul>\n<li><code>np.hanning</code>, <code>np.hamming</code>, <code>np.bartlett</code>, <code>np.blackman</code>,\n<code>np.kaiser</code>: Tapered windowing functions.</li>\n</ul>\n<p>It is also used to perform fast convolutions of large inputs by\n<code>scipy.signal.fftconvolve</code>.</p>\n<p>SciPy wraps the Fortran FFTPACK library—it is not the fastest out\nthere, but unlike packages such as FFTW, it has a permissive free\nsoftware license.</p>\n<h2>Choosing the length of the discrete Fourier transform (DFT)</h2>\n<p>A naive calculation of the DFT takes $\\mathcal{O}\\left(N^2\\right)$ operations <sup id=\"fnref-big_o\"><a href=\"#fn-big_o\" class=\"footnote-ref\">big_o</a></sup>.\nHow come? Well, you have $N$\n(complex) sinusoids of different frequencies ($2 \\pi f \\times 0, 2 \\pi f \\times\n1, 2 \\pi f \\times 3, ..., 2 \\pi f \\times (N - 1)$), and you want to see how\nstrongly your signal corresponds to each. Starting with the first,\nyou take the dot product with the signal (which, in itself, entails $N$\nmultiplication operations). Repeating this operation $N$ times, once\nfor each sinusoid, then gives $N^2$ operations.</p>\n<p>Now, contrast that with the fast Fourier transform, which is $\\mathcal{O}\\left(N \\log N\\right)$ in\nthe ideal case due to the clever re-use of\ncalculations—a great improvement! However, the classical Cooley-Tukey\nalgorithm implemented in FFTPACK (and used by SciPy) recursively breaks up the transform\ninto smaller (prime-sized) pieces and only shows this improvement for\n\"smooth\" input lengths (an input length is considered smooth when its\nlargest prime factor is small). For large prime-sized pieces, the\nBluestein or Rader algorithms can be used in conjunction with the\nCooley-Tukey algorithm, but this optimization is not implemented in\nFFTPACK.<sup id=\"fnref-fast\"><a href=\"#fn-fast\" class=\"footnote-ref\">fast</a></sup></p>\n<p>Let us illustrate:</p>\n<pre><code class=\"language-python\">import time\n\nfrom scipy import fftpack\nfrom sympy import factorint\n\nK = 1000\nlengths = range(250, 260)\n\n# Calculate the smoothness for all input lengths\nsmoothness = [max(factorint(i).keys()) for i in lengths]\n\nexec_times = []\nfor i in lengths:\n    z = np.random.random(i)\n\n    # For each input length i, execute the FFT K times\n    # and store the execution time\n\n    times = []\n    for k in range(K):\n        tic = time.monotonic()\n        fftpack.fft(z)\n        toc = time.monotonic()\n        times.append(toc - tic)\n\n    # For each input length, remember the *minimum* execution time\n    exec_times.append(min(times))\n\nf, (ax0, ax1) = plt.subplots(2, 1, sharex=True)\nax0.stem(lengths, np.array(exec_times) * 10**6)\nax0.set_ylabel('Execution time (µs)')\n\nax1.stem(lengths, smoothness)\nax1.set_ylabel('Smoothness of input length\\n(lower is better)')\nax1.set_xlabel('Length of input');\n</code></pre>\n<!-- caption text=\"FFT execution time vs smoothness for different input lengths\" -->\n<p>The intuition is that, for smooth input lengths, the FFT can be broken up\ninto many small pieces. After performing the FFT on the first piece,\nthose results can be reused in subsequent computations. This explains\nwhy we chose a length of 1024 for our audio slices earlier—it has a\nsmoothness of only 2, resulting in the optimal \"radix-2 Cooley-Tukey\"\nalgorithm, which computes the FFT using only $(N/2) \\log_2 N = 5120$ complex\nmultiplications, instead of $N^2 = 1048576$. Choosing $N = 2^m$\nalways ensures a maximally smooth $N$ (and, thus, the fastest FFT).</p>\n<h2>More discrete Fourier transform concepts</h2>\n<p>Next, we present a couple of common concepts worth knowing before\noperating heavy Fourier transform machinery, whereafter we tackle\nanother real-world problem: analyzing target detection in radar data.</p>\n<h3>Frequencies and their ordering</h3>\n<p>For historical reasons, most implementations return an array where\nfrequencies vary from low-to-high-to-low (see the box \"Discrete\nFourier transforms\" for further explanation of frequencies). E.g., when we do the real\nFourier transform of a signal of all ones, an input that has no\nvariation and therefore only has the slowest, constant Fourier\ncomponent (also known as the \"DC\" or Direct Current component—just\nelectronics jargon for \"mean of the signal\"), we see this DC component\nappearing as the first entry:</p>\n<pre><code class=\"language-python\">from scipy import fftpack\nN = 10\n\nfftpack.fft(np.ones(N))  # The first component is np.mean(x) * N\n</code></pre>\n<p>When we try the FFT on a rapidly changing signal, we see a high\nfrequency component appear:</p>\n<pre><code class=\"language-python\">z = np.ones(10)\nz[::2] = -1\n\nprint(f'Applying FFT to {z}')\nfftpack.fft(z)\n</code></pre>\n<p>Note that the FFT returns a complex spectrum which, in the case of\nreal inputs, is conjugate symmetrical (i.e., symmetric in the real\npart, and anti-symmetric in the imaginary part):</p>\n<pre><code class=\"language-python\">x = np.array([1, 5, 12, 7, 3, 0, 4, 3, 2, 8])\nX = fftpack.fft(x)\n\nwith np.printoptions(precision=2):\n    print(\"Real part:     \", X.real)\n    print(\"Imaginary part:\", X.imag)\n</code></pre>\n<p>(And, again, recall that the first component is <code>np.mean(x) * N</code>.)</p>\n<p>The <code>fftfreq</code> function tells us which frequencies we are looking at\nspecifically:</p>\n<pre><code class=\"language-python\">fftpack.fftfreq(10)\n</code></pre>\n<p>The result tells us that our maximum component occured at a frequency\nof 0.5 cycles per sample. This agrees with the input, where a\nminus-one-plus-one cycle repeated every second sample.</p>\n<p>Sometimes, it is convenient to view the spectrum organized slightly\ndifferently, from high-negative to low to-high-positive (for now, we\nwon't dive too deeply into the concept of negative frequency, other\nthan saying a real-world sine wave is produced by a combination of\npositive and negative frequencies). We re-shuffle the spectrum using\nthe <code>fftshift</code> function.</p>\n<blockquote>\n<p><strong>Discrete Fourier transforms {.callout}</strong></p>\n<p>The Discrete Fourier Transform (DFT) converts a sequence of $N$\nequally spaced real or complex samples $x<em>{0},x</em>{1},\\ldots, x<em>{N-1}$ of\na function $x(t)$ of time (or another variable, depending on the\napplication) into a sequence of $N$ complex numbers $X</em>{k}$ by the\nsummation</p>\n<p>$$\nX<em>{k}=\\sum</em>{n=0}^{N-1}x_{n}e^{-j2\\pi kn/N},;k=0,1,\\ldots,\nN-1.\n$$</p>\n<p>With the numbers $X<em>{k}$ known, the inverse DFT _exactly</em> recovers the\nsample values $x_{n}$ through the summation</p>\n<p>$$x<em>{n}=\\frac{1}{N}\\sum</em>{k=0}^{N-1}X_{k}e^{j2\\pi kn/N}.$$</p>\n<p>Keeping in mind that $e^{j\\theta}=\\cos\\theta+j\\sin\\theta,$ the last\nequation shows that the DFT has decomposed the sequence $x<em>{n}$ into a\ncomplex discrete Fourier series with coefficients $X</em>{k}$. Comparing\nthe DFT with a continuous complex Fourier series</p>\n<p>$$x(t)=\\sum<em>{n=-\\infty}^{\\infty}c</em>{n}e^{jn\\omega_{0}t},$$</p>\n<p>the DFT is a <em>finite</em> series with $N$ terms defined at the equally\nspaced discrete instances of the <em>angle</em> $(\\omega<em>{0}t</em>{n})=2\\pi\\frac{k}{N}$\nin the interval $[0,2\\pi)$,\ni.e. <em>including</em> $0$ and <em>excluding</em> $2\\pi$.\nThis automatically normalizes the DFT so that time does\nnot appear explicitly in the forward or inverse transform.</p>\n<p>If the original function $x(t)$ is limited in frequency to less than\nhalf of the sampling frequency (the so-called <em>Nyquist frequency</em>),\ninterpolation between sample values produced by the inverse DFT will\nusually give a faithful reconstruction of $x(t)$. If $x(t)$ is <em>not</em>\nlimited as such, the inverse DFT can, in general, not be used to\nreconstruct $x(t)$ by interpolation. Note that this limit does not\nimply that there are <em>no</em> methods that can do such a\nreconstruction—see, e.g., compressed sensing, or finite rate of\ninnovation sampling.</p>\n<p>The function $e^{j2\\pi k/N}=\\left(e^{j2\\pi/N}\\right)^{k}=w^{k}$ takes on\ndiscrete values between $0$ and $2\\pi\\frac{N-1}{N}$ on the unit circle in\nthe complex plane. The function $e^{j2\\pi kn/N}=w^{kn}$ encircles the\norigin $n\\frac{N-1}{N}$ times, thus generating harmonics of the fundamental\nsinusoid for which $n=1$.</p>\n<p>The way in which we defined the DFT leads to a few subtleties\nwhen $n>\\frac{N}{2}$, for even $N$ <sup id=\"fnref-odd_n\"><a href=\"#fn-odd_n\" class=\"footnote-ref\">odd_n</a></sup>. The function $e^{j2\\pi kn/N}$ is plotted\nfor increasing values of $k$ in the figure below,\nfor the cases $n=1$ to $n=N-1$ for $N=16$. When $k$ increases from $k$\nto $k+1$, the angle increases by $\\frac{2\\pi n}{N}$. When $n=1$,\nthe step is $\\frac{2\\pi}{N}$. When $n=N-1$, the angle\nincreases by $2\\pi\\frac{N-1}{N}=2\\pi-\\frac{2\\pi}{N}$. Since $2\\pi$\nis precisely once around the circle, the step equates to $-\\frac{2\\pi}{N}$,\ni.e. in the direction of a negative\nfrequency. The components up to $N/2$ represent <em>positive</em> frequency\ncomponents, those above $N/2$ up to $N-1$ represent <em>negative</em>\nfrequencies. The angle increment for the component $N/2$\nfor $N$ even advances precisely halfway around the circle for\neach increment in $k$ and can therefore be interpreted as either a\npositive or a negative frequency. This component of the DFT represents\nthe Nyquist Frequency, i.e. half of the sampling frequency, and is\nuseful to orientate oneself when looking at DFT graphics.</p>\n<p>The FFT in turn is simply a special and highly efficient algorithm for\ncalculating the DFT. Whereas a straightforward calculation of the DFT\ntakes of the order of $N^{2}$ calculations to compute, the FFT\nalgorithm requires of the order $N\\log N$ calculations. The FFT was\nthe key to the wide-spread use of the DFT in real-time applications\nand was included in a list of the top $10$ algorithms of the $20^{th}$\ncentury by the IEEE journal Computing in Science &#x26; Engineering in the\nyear $2000$.</p>\n<p><img src=\"../figures/unit_circle_samples.png\" alt=\"Unit circle samples\"></p>\n</blockquote>\n<p>Let's examine the frequency components in a noisy image. Note that,\nwhile a static image has no time-varying component, its values do vary\nacross <em>space</em>. The DFT applies equally to either case.</p>\n<p>First, load and display the image:</p>\n<pre><code class=\"language-python\">from skimage import io\nimage = io.imread('images/moonlanding.png')\nM, N = image.shape\n\nf, ax = plt.subplots(figsize=(4.8, 4.8))\nax.imshow(image)\n\nprint((M, N), image.dtype)\n</code></pre>\n<!-- caption text=\"A noisy image of the moon landing\" -->\n<p>Do not adjust your monitor! The image you are seeing is real,\nalthough clearly distorted by either the measurement or transmission\nequipment.</p>\n<p>To examine the spectrum of the image, we use <code>fftn</code> (instead of <code>fft</code>)\nto compute the DFT, since it has more than one dimension. The\ntwo-dimensional FFT is equivalent to taking the 1-D FFT across rows\nand then across columns (or vice versa).</p>\n<pre><code class=\"language-python\">F = fftpack.fftn(image)\n\nF_magnitude = np.abs(F)\nF_magnitude = fftpack.fftshift(F_magnitude)\n</code></pre>\n<p>Again, we take the log of the spectrum to compress the range of\nvalues, before displaying:</p>\n<pre><code class=\"language-python\">f, ax = plt.subplots(figsize=(4.8, 4.8))\n\nax.imshow(np.log(1 + F_magnitude), cmap='viridis',\n          extent=(-N // 2, N // 2, -M // 2, M // 2))\nax.set_title('Spectrum magnitude');\n</code></pre>\n<!-- caption text=\"Spectrum of the noisy moon landing image (magnitude)\" -->\n<p>Note the high values around the origin (middle) of the spectrum—these\ncoefficients describe the low frequencies or smooth parts of the\nimage; a vague canvas of the photo. Higher frequency components,\nspread throughout the spectrum, fill in the edges and detail. Peaks\naround higher frequencies correspond to the periodic noise.</p>\n<p>From the photo, we can see that the noise (measurement artifacts) is\nhighly periodic, so we hope to remove it by zeroing out the\ncorresponding parts of the spectrum.</p>\n<p>The image with those peaks suppressed indeed looks quite different!</p>\n<pre><code class=\"language-python\"># Set block around center of spectrum to zero\nK = 40\nF_magnitude[M // 2 - K: M // 2 + K, N // 2 - K: N // 2 + K] = 0\n\n# Find all peaks higher than the 98th percentile\npeaks = F_magnitude &#x3C; np.percentile(F_magnitude, 98)\n\n# Shift the peaks back to align with the original spectrum\npeaks = fftpack.ifftshift(peaks)\n\n# Make a copy of the original (complex) spectrum\nF_dim = F.copy()\n\n# Set those peak coefficients to zero\nF_dim = F_dim * peaks.astype(int)\n\n# Do the inverse Fourier transform to get back to an image\n# Since we started with a real image, we only look at the real part of\n# the output.\nimage_filtered = np.real(fftpack.ifft2(F_dim))\n\nf, (ax0, ax1) = plt.subplots(2, 1, figsize=(4.8, 7))\nax0.imshow(fftpack.fftshift(np.log10(1 + np.abs(F_dim))), cmap='viridis')\nax0.set_title('Spectrum after suppression')\n\nax1.imshow(image_filtered)\nax1.set_title('Reconstructed image');\n</code></pre>\n<!-- caption text=\"Filtered moon landing image and its spectrum\" -->\n<h3>Windowing</h3>\n<p>If we examine the Fourier transform of a rectangular pulse, we see\nsignificant sidelobes in the spectrum:</p>\n<pre><code class=\"language-python\">x = np.zeros(500)\nx[100:150] = 1\n\nX = fftpack.fft(x)\n\nf, (ax0, ax1) = plt.subplots(2, 1, sharex=True)\n\nax0.plot(x)\nax0.set_ylim(-0.1, 1.1)\n\nax1.plot(fftpack.fftshift(np.abs(X)))\nax1.set_ylim(-5, 55);\n</code></pre>\n<!-- caption text=\"Spectrum of a rectangular pulse (magnitude)\" -->\n<p>In theory, you would need a combination of infinitely many sinusoids\n(frequencies) to represent any abrupt transition; the coefficients would\ntypically have the same sidelobe structure as seen here for the pulse.</p>\n<p>Importantly, the discrete Fourier transform assumes that the input\nsignal is periodic. If the signal is not, the assumption is simply\nthat, right at the end of the signal, it jumps back to its beginning\nvalue. Consider the function, $x(t)$, shown here:</p>\n<img src=\"../figures/periodic.png\"/>\n<!-- caption text=\"Eight samples have been taken of a given\n function with effective length $T_{eff}$.  With the discrete Fourier\n transform assuming periodicity, it creates a step discontinuity\n between the first and last samples.\" -->\n<p>We only measure the signal for a short time, labeled $T_{eff}$. The\nFourier transform assumes that $x(8) = x(0)$, and that the signal is\ncontinued as the dashed, rather than the solid line. This introduces\na big jump at the edge, with the expected oscillation in the spectrum:</p>\n<pre><code class=\"language-python\">t = np.linspace(0, 1, 500)\nx = np.sin(49 * np.pi * t)\n\nX = fftpack.fft(x)\n\nf, (ax0, ax1) = plt.subplots(2, 1)\n\nax0.plot(x)\nax0.set_ylim(-1.1, 1.1)\n\nax1.plot(fftpack.fftfreq(len(t)), np.abs(X))\nax1.set_ylim(0, 190);\n</code></pre>\n<!-- caption text=\"Spectrum oscillation due to signal edge discontinuity\" -->\n<p>Instead of the expected two lines, the peaks are spread out in the\nspectrum.</p>\n<p>We can counter this effect by a process called <em>windowing</em>. The\noriginal function is multiplied with a window function such as the\nKaiser window $K(N,\\beta)$. Here we visualize it for $\\beta$ ranging\nfrom 0 to 100:</p>\n<pre><code class=\"language-python\">f, ax = plt.subplots()\n\nN = 10\nbeta_max = 5\ncolormap = plt.cm.plasma\n\nnorm = plt.Normalize(vmin=0, vmax=beta_max)\n\nlines = [\n    ax.plot(np.kaiser(100, beta), color=colormap(norm(beta)))\n    for beta in np.linspace(0, beta_max, N)\n    ]\n\nsm = plt.cm.ScalarMappable(cmap=colormap, norm=norm)\n\nsm._A = []\n\nplt.colorbar(sm).set_label(r'Kaiser $\\beta$');\n</code></pre>\n<!-- caption text=\"The Kaiser window for various values of $\\beta$\" -->\n<p>By changing the parameter $\\beta$, the shape of the window can be\nchanged from rectangular ($\\beta=0$, no windowing) to a window that\nproduces signals that smoothly increase from zero and decrease to zero\nat the endpoints of the sampled interval, producing very low side\nlobes ($\\beta$ typically between 5 and 10) <sup id=\"fnref-choosing_a_window\"><a href=\"#fn-choosing_a_window\" class=\"footnote-ref\">choosing_a_window</a></sup>.</p>\n<!--\n*For online notebook, use something like:*\n\n#```\n# @interact(beta=(0, 20.))\n# def window(beta):\n#    x = np.kaiser(1000, beta)\n#    f, axes = plt.subplots(1, 2, figsize=(4.8, 2.4))\n#    axes[0].plot(x)\n#    axes[1].plot(fftpack.fftshift(np.abs(np.fft.fft(x, 10000))))\n#    axes[1].set_xlim(2*2480, 2*2520)\n#    plt.show()\n#```\n-->\n<p>The effect of windowing our previous example is noticeable:</p>\n<pre><code class=\"language-python\">win = np.kaiser(len(t), 5)\nx_win = x * win\n\nX_win = fftpack.fft(x_win)\n\nf, (ax0, ax1) = plt.subplots(2, 1)\n\nax0.plot(x_win)\nax0.set_ylim(-1.1, 1.1)\n\nax1.plot(fftpack.fftfreq(len(t)), np.abs(X_win))\nax1.set_ylim(0, 190);\n</code></pre>\n<!-- caption text=\"Spectrum of a windowed signal (magnitude)\" -->\n<h2>Real-world Application: Analyzing Radar Data</h2>\n<p>Linearly modulated FMCW (Frequency-Modulated Continuous-Wave) radars\nmake extensive use of the FFT algorithm for signal processing and\nprovide examples of various applications of the FFT. We will use actual\ndata from an FMCW radar to demonstrate one such an application: target\ndetection.</p>\n<p>Roughly, an FMCW radar works like this (see box \"A\nsimple FMCW radar system\" for more detail):</p>\n<p>A signal with changing frequency is generated. This signal is\ntransmitted by an antenna, after which it travels outwards, away from the\nradar. When it hits an object, part of the signal is reflected back\nto the radar, where it is received, multiplied by a copy of the\ntransmitted signal, and sampled, turning it into\nnumbers that are packed into an array. Our challenge is to interpret\nthose numbers to form meaningful results.</p>\n<p>The multiplication step above is important. From school, recall the\ntrigonometric identity:</p>\n<p>$\n\\sin(xt) \\sin(yt) = \\frac{1}{2}\n\\left[ \\sin \\left( (x - y)t + \\frac{\\pi}{2} \\right) - \\sin \\left( (x + y)t + \\frac{\\pi}{2} \\right) \\right]\n$</p>\n<p>Thus, if we multiply the received signal by the transmitted signal, we\nexpect two frequency components to appear in the spectrum: one that is\nthe difference in frequencies between the received and transmitted\nsignal, and one that is the sum of their frequencies.</p>\n<p>We are particularly interested in the first, since that gives us some\nindication of how long it took the signal to reflect back to the radar\n(in other words, how far away the object is from us!). We discard the\nother by applying a low-pass filter to the signal (i.e., a filter that\ndiscards any high frequencies).</p>\n<blockquote>\n<p><strong>A simple FMCW radar system</strong> {.callout}</p>\n<p><img src=\"../figures/FMCW_Block.png\" alt=\"The block diagram of a simple FMCW radar system\"></p>\n<p>A block diagram of a simple FMCW radar that uses separate\ntransmit and receive antennas is shown above. The radar consists of a waveform generator\nthat generates a sinusoidal signal of which the frequency varies\nlinearly around the required transmit frequency. The generated signal\nis amplified to the required power level by the transmit amplifier\nand routed to the transmit antenna via a coupler circuit where a copy\nof the transmit signal is tapped off. The transmit antenna radiates\nthe transmit signal as an electromagnetic wave in a narrow beam\ntowards the target to be detected. When the wave encounters an object\nthat reflects electromagnetic waves, a fraction of of the energy\nirradiating the target is reflected back to the receiver as a second\nelectromagnetic wave that propagates in the direction of the radar\nsystem. When this wave encounters the receive antenna, the antenna\ncollects the energy in the wave energy impinging on it and converts\nit to a fluctuating voltage that is fed to the mixer. The mixer\nmultiplies the received signal with a replica of the transmit signal\nand produces a sinusoidal signal with a frequency equal to the\ndifference in frequency between the transmitted and received\nsignals. The low-pass filter ensures that the received signal is band\nlimited (i.e., does not contain frequencies that we don't care about)\nand the receive amplifier strengthens the signal to a suitable\namplitude for the analog to digital converter (ADC) that feeds data\nto the computer.</p>\n</blockquote>\n<p>To summarize, we should note that:</p>\n<ul>\n<li>The data that reaches the computer consists of $N$ samples sampled\n(from the multiplied, filtered signal) at a sample frequency of\n$f_{s}$.</li>\n<li>The <strong>amplitude</strong> of the returned signal varies depending on the\n<strong>strength of the reflection</strong> (i.e., is a property of the target\nobject and the distance between the target and the radar).</li>\n<li>The <strong>frequency measured</strong> is an indication of the <strong>distance</strong> of the\ntarget object from the radar.</li>\n</ul>\n<!--\n\n### Signal properties in the time domain\n\nThe transmit signal is a sinusoidal signal with an instantaneous\nfrequency that increases linearly with time, as shown in\nFig. [fig:FMCW waveform](a).\n\nStarting at $f_{min}$, the frequency increases at a rate $S$ Hz/s to $f_{max}.$\nThe frequency is then decreased rapidly back to $f_{min}$\nafter which a next frequency sweep occurs.\n\nThis signal is radiated by a directional transmit antenna. When the\nwave with propagation velocity $v\\approx300\\times10^{6}$ m/s (the\npropagation speed of electromagnetic waves in air is ever-so-slightly\nslower than the speed of light in a vacuum) hits a target at a range $R$,\nthe echo will reach the radar after a time\n\n$$t_{d}=\\frac{2R}{v}.$$\n\nHere it is collected by the receive antenna and converted to a\nsinusoidally fluctuating voltage. The received signal is a replica of\nthe transmitted signal, delayed by the transit time $t_{d}$ and is\nshown dashed in Fig. [fig:FMCW waveform](b).\n\nA radar is designed to detect targets up to a maximum range $R_{max}$.\nEchoes from maximum range reach the radar after a transit\ntime $t_{dm}$ as shown in Fig. [fig:FMCW waveform](c).\n\nWe note that there is a constant difference in frequency between the\ntransmitted and received signals and this will be true for all targets\nafter time $t_{s}$ until $t_{e}$. We conclude from\nFig. [fig:FMCW waveform] that the frequency difference is given by\n\n$$f_{d}=S\\times t_{d}=\\frac{2SR}{v},$$\n\nwhere $T_{eff}=t_{e}-t_{s}=\\frac{N}{f_{s}}$ is the effective sweep duration\nof the radar. The frequency excursion of the sweep during $T_{eff}$ is\nthe effective bandwidth of the radar, given by\n\n$$B_{eff}=f_{max}-f_{1}=ST_{eff}.$$\n\nWe will see that the range resolution of the radar is determined by\nthe effective bandwidth.\n\nReturning to Fig. [fig: block-diagram], the signal produced by the\nreceiver at the input to the Analog to Digital Converter (ADC) when\nthere is a single target is a sinusoid with constant amplitude,\nproportional to the amplitude of the echo, and constant frequency,\nproportional to the range to the target.\n\n-->\n<p><img src=\"../figures/FMCW_waveform.png\" alt=\"The frequency relationships in an FMCW radar with\n linear frequency modulation\"></p>\n<p>To start off, we'll generate some synthetic signals, after which we'll\nturn our focus to the output of an actual radar.</p>\n<p>Recall that the radar is increasing its frequency as it transmits at a\nrate of $S$ Hz/s. After a certain amount of time, $t$, has passed,\nthe frequency will now be $t S$ higher. In that same time span, the\nradar signal has traveled $d = t / v$ meters, where $v$ is the speed of\nthe transmitted wave through air (roughly the same as the speed of\nlight, $3 \\times 10^8$ m/s).</p>\n<p>Combining the above observations, we can calculate the amount of time\nit would take the signal to travel to, bounce off, and return from a\ntarget that is distance $R$ away:</p>\n<p>$$ t_R = 2R / v $$</p>\n<p>Therefore, the change in frequency for a target at range $R$ will be:</p>\n<p>$$ f_{d}= t_R S = \\frac{2RS}{v}$$</p>\n<pre><code class=\"language-python\">pi = np.pi\n\n# Radar parameters\nfs = 78125          # Sampling frequency in Hz, i.e. we sample 78125\n                    # times per second\n\nts = 1 / fs         # Sampling time, i.e. one sample is taken each\n                    # ts seconds\n\nTeff = 2048.0 * ts  # Total sampling time for 2048 samples\n                    # (AKA effective sweep duration) in seconds.\n\nBeff = 100e6        # Range of transmit signal frequency during the time the\n                    # radar samples, known as the \"effective bandwidth\"\n                    # (given in Hz)\n\nS = Beff / Teff     # Frequency sweep rate in Hz/s\n\n# Specification of targets.  We made these targets up, imagining they\n# are objects seen by the radar with the specified range and size\n\nR = np.array([100, 137, 154, 159,  180])  # Ranges (in meter)\nM = np.array([0.33, 0.2, 0.9, 0.02, 0.1])  # Target size\nP = np.array([0, pi / 2, pi / 3, pi / 5, pi / 6])  # Randomly chosen phase offsets\n\nt = np.arange(2048) * ts  # Sample times\n\nfd = 2 * S * R / 3E8      # Frequency differences for these targets\n\n# Generate five targets\nsignals = np.cos(2 * pi * fd * t[:, np.newaxis] + P)\n\n# Save the signal associated with the first target as an example for\n# later inspection\nv_single = signals[:, 0]\n\n# Weigh the signals, according to target size, and sum, to generate\n# the combined signal seen by the radar\nv_sim = np.sum(M * signals, axis=1)\n\n## The above code is equivalent to:\n#\n# v0 = np.cos(2 * pi * fd[0] * t)\n# v1 = np.cos(2 * pi * fd[1] * t + pi / 2)\n# v2 = np.cos(2 * pi * fd[2] * t + pi / 3)\n# v3 = np.cos(2 * pi * fd[3] * t + pi / 5)\n# v4 = np.cos(2 * pi * fd[4] * t + pi / 6)\n#\n## Blend them together\n# v_single = v0\n# v_sim = (0.33 * v0) + (0.2 * v1) + (0.9 * v2) + (0.02 * v3) + (0.1 * v4)\n</code></pre>\n<p>Above, we generate a synthetic signal, $v_\\mathrm{single}$, received when\nlooking at a single target (see figure below). By counting the number\nof cycles seen in a given time period, we can compute the frequency of\nthe signal and thus the distance to the target.</p>\n<p>A real radar will rarely receive only a single echo, though. The\nsimulated signal $v<em>\\mathrm{sim}$ shows what a radar signal will look\nlike with five targets at different ranges (including two close to one\nanother at 154 and 159 meters), and $v</em>\\mathrm{actual}(t)$ shows the\noutput signal obtained with an actual radar. When multiple echoes add\ntogether, the result makes little intuitive sense; until, that is, we\nlook at it more carefully through the lens of the discrete Fourier\ntransform.</p>\n<!--\nA synthetic radar signal is shown as $v_{1}(t)$ in Fig. [fig:radar time signals]\nfor a radar with parameters $B_{eff}=100$ MHz, sampling frequency\n28125 Hz and N=2048 samples. The effective sweep time is\n$T_{eff}=\\frac{2048}{28125}=26.214$ ms. We can interpret this signal\nby counting the number of cycles in the graph — about\n$66\\frac{1}{2}$. The difference frequency is approximately\n$\\frac{66.5}{26.214E-3}=6.35$ kHz. With\n$S=\\frac{B_{eff}}{T_{eff}}=\\frac{100E6}{26.214E-3}=3.815\\times10^{9}$\nHz/s, we can calculate the range to the target as\n$R=\\frac{vf_{d}}{2S}=\\frac{3\\times10^{8}\\times6.35\\times10^{3}}{2\\times3.815\\times10^{9}}=249.7$\nm.\n-->\n<p><img src=\"../figures/generated/radar_time_signals.png\" alt=\"Receiver output signals: (a) single simulated target\n (b) five simulated targets (c) actual radar data\"></p>\n<p>The real-world radar data is read from a NumPy-format <code>.npz</code> file (a\nlight-weight, cross-platform and cross-version compatible storage\nformat). These files can be saved with the <code>np.savez</code> or\n<code>np.savez_compressed</code> functions. Note that SciPy's <code>io</code> submodule\ncan also easily read other formats, such as MATLAB(R) and NetCDF\nfiles.</p>\n<pre><code class=\"language-python\">data = np.load('data/radar_scan_0.npz')\n\n# Load variable 'scan' from 'radar_scan_0.npz'\nscan = data['scan']\n\n# The dataset contains multiple measurements, each taken with the\n# radar pointing in a different direction.  Here we take one such as\n# measurement, at a specified azimuth (left-right position) and elevation\n# (up-down position).  The measurement has shape (2048,).\n\nv_actual = scan['samples'][5, 14, :]\n\n# The signal amplitude ranges from -2.5V to +2.5V.  The 14-bit\n# analogue-to-digital converter in the radar gives out integers\n# between -8192 to 8192.  We convert back to voltage by multiplying by\n# $(2.5 / 8192)$.\n\nv_actual = v_actual * (2.5 / 8192)\n</code></pre>\n<p>Since <code>.npz</code>-files can store multiple variables, we have to select\nthe one we want: <code>data['scan']</code>. That returns a\n<em>structured NumPy array</em> with the following fields:</p>\n<ul>\n<li><strong>time</strong> : unsigned 64-bit (8 byte) integer (<code>np.uint64</code>)</li>\n<li><strong>size</strong> : unsigned 32-bit (4 byte) integer (<code>np.uint32</code>)</li>\n<li>\n<p><strong>position</strong></p>\n<ul>\n<li><strong>az</strong> : 32-bit float (<code>np.float32</code>)</li>\n<li><strong>el</strong> : 32-bit float (<code>np.float32</code>)</li>\n<li><strong>region_type</strong> : unsigned 8-bit (1 byte) integer (<code>np.uint8</code>)</li>\n<li><strong>region_ID</strong> : unsigned 16-bit (2 byte) integer (<code>np.uint16</code>)</li>\n<li><strong>gain</strong> : unsigned 8-bit (1 byte) integer (<code>np.uin8</code>)</li>\n<li><strong>samples</strong> : 2048 unsigned 16-bit (2 byte) integers (<code>np.uint16</code>)</li>\n</ul>\n</li>\n</ul>\n<p>While it is true that NumPy arrays are <em>homogeneous</em> (i.e., all the\nelements inside are the same), it does not mean that those elements\ncannot be compound elements, as is the case here.</p>\n<p>An individual field is accessed using dictionary syntax:</p>\n<pre><code class=\"language-python\">azimuths = scan['position']['az']  # Get all azimuth measurements\n</code></pre>\n<p>To summarize what we've seen so far: the shown measurements\n($v<em>\\mathrm{sim}$ and $v</em>\\mathrm{actual}$) are the sum of sinusoidal\nsignals reflected by each of several objects. We need to determine\neach of the constituent components of these composite radar\nsignals. The FFT is the tool that will do this for us.</p>\n<h3>Signal properties in the frequency domain</h3>\n<p>First, we take the FFTs of our three signals (synthetic single target,\nsynthetic multi-target, and real) and then display the\npositive frequency components (i.e., components $0$ to $N/2$). These\nare called the <em>range traces</em> in radar terminology.</p>\n<pre><code class=\"language-python\">fig, axes = plt.subplots(3, 1, sharex=True, figsize=(4.8, 2.4))\n\n# Take FFTs of our signals.  Note the convention to name FFTs with a\n# capital letter.\n\nV_single = np.fft.fft(v_single)\nV_sim = np.fft.fft(v_sim)\nV_actual = np.fft.fft(v_actual)\n\nN = len(V_single)\n\nwith plt.style.context('style/thinner.mplstyle'):\n    axes[0].plot(np.abs(V_single[:N // 2]))\n    axes[0].set_ylabel(\"$|V_\\mathrm{single}|$\")\n    axes[0].set_xlim(0, N // 2)\n    axes[0].set_ylim(0, 1100)\n\n    axes[1].plot(np.abs(V_sim[:N // 2]))\n    axes[1].set_ylabel(\"$|V_\\mathrm{sim} |$\")\n    axes[1].set_ylim(0, 1000)\n\n    axes[2].plot(np.abs(V_actual[:N // 2]))\n    axes[2].set_ylim(0, 750)\n    axes[2].set_ylabel(\"$|V_\\mathrm{actual}|$\")\n\n    axes[2].set_xlabel(\"FFT component $n$\")\n\n    for ax in axes:\n        ax.grid()\n</code></pre>\n<!-- caption text=\"Range traces for: (a) single simulated target, (b) mutiple simulated targets, (c) real-world targets\" -->\n<p>Suddenly, the information makes sense!</p>\n<p>The plot for $|V<em>\\mathrm{single}|$ clearly shows a target at component 67, and\nfor $|V</em>\\mathrm{sim}|$ shows the targets that produced the signal that was\nuninterpretable in the time domain. The real radar\nsignal, $|V_\\mathrm{actual}|$ shows a large number of targets between\ncomponent 400 and 500 with a large peak in component 443. This happens\nto be an echo return from a radar illuminating the high wall of an\nopen-cast mine.</p>\n<p>To get useful information from the plot, we must determine the range!\nAgain, we use the formula:</p>\n<p>$$R<em>{n}=\\frac{nv}{2B</em>{eff}}$$</p>\n<p>In radar terminology, each DFT component is known as a <em>range bin</em>.</p>\n<!--\nThe sinusoid associated with the first component of the DFT has a\nperiod exactly equal to the duration $T_{eff}$ of the time domain\nsignal, so $f_{1}=\\frac{1}{T_{eff}}$. The other sinusoids in the\nFourier series are harmonics of this, $f_{n}=\\frac{n}{T_{eff}}$.\n\nThe ranges associated with the DFT components follow from\nEqs. ([eq:difference frequency]) and ([eq:Effective bandwidth]) as\n\n$$R_{n}=\\frac{nv}{2B_{eff}}$$\n\nand the associated DFT components are known as *range bins* in radar\nterminology.\n\n-->\n<p>This equation also defines the range resolution of the radar: targets\nwill only be distinguishable if they are separated by more than two\nrange bins, i.e.</p>\n<p>$$\\Delta R>\\frac{1}{B_{eff}}.$$</p>\n<p>This is a fundamental property of all types of radar.</p>\n<!--\nThe plot in Fig. ([fig:FFT range traces]) has a fundamental\nshortcoming. The observable dynamic range is the signal is very\nlimited! We could easily have missed one of the targets in the trace\nfor $V_{5}$!  To ameliorate the problem, we plot the same FFTs but\nthis time against a logarithmic y-axis.  The traces were all\nnormalized by dividing the amplitudes with the maximum value.\n-->\n<p>This result is quite satisfying—but the dynamic range is so large\nthat we could very easily miss some peaks. Let's take the $\\log$ as\nbefore with the spectrogram:</p>\n<pre><code class=\"language-python\">c = 3e8  # Approximately the speed of light and of\n         # electromagnetic waves in air\n\nfig, (ax0, ax1, ax2) = plt.subplots(3, 1)\n\ndef dB(y):\n    \"Calculate the log ratio of y / max(y) in decibel.\"\n\n    y = np.abs(y)\n    y /= y.max()\n\n    return 20 * np.log10(y)\n\ndef log_plot_normalized(x, y, ylabel, ax):\n    ax.plot(x, dB(y))\n    ax.set_ylabel(ylabel)\n    ax.grid()\n\nrng = np.arange(N // 2) * c / 2 / Beff\n\nwith plt.style.context('style/thinner.mplstyle'):\n    log_plot_normalized(rng, V_single[:N // 2], \"$|V_0|$ [dB]\", ax0)\n    log_plot_normalized(rng, V_sim[:N // 2], \"$|V_5|$ [dB]\", ax1)\n    log_plot_normalized(rng, V_actual[:N // 2], \"$|V_{\\mathrm{actual}}|$ [dB]\", ax2)\n\nax0.set_xlim(0, 300)  # Change x limits for these plots so that\nax1.set_xlim(0, 300)  # we are better able to see the shape of the peaks.\nax2.set_xlim(0, len(V_actual) // 2)\nax2.set_xlabel('range')\n</code></pre>\n<!-- caption text=\"Logarithm of range traces\" -->\n<p>The observable dynamic range is much improved in these plots. For\ninstance, in the real radar signal the <em>noise floor</em> of the radar has\nbecome visible (i.e., the level where electronic noise in the system\nstarts to limit the radar's ability to detect a target).</p>\n<!-- The noise floor is ultimately caused by a phenomenon\ncalled thermal noise that is produced by all conducting elements that\nhave resistance at temperatures above absolute zero, as well as by\nshot noise, a noise mechanism inherent in all the electronic devices\nthat are used for processing the radar signal. The noise floor of a\nradar limits its ability to detect weak echoes. -->\n<h3>Windowing, applied</h3>\n<p>We're getting there, but in the spectrum of the simulated signal, we\nstill cannot distinguish the peaks at 154 and 159 meters. Who knows\nwhat we're missing in the real-world signal! To sharpen the peaks,\nwe'll return to our toolbox and make use of <em>windowing</em>.</p>\n<!--\n\nThe range traces in Fig. ([fig:Log range traces]) display a further\nserious shortcoming. The signals $v_{1}$ and $v_{5}$ are composed of\npure sinusoids and we would ideally expect the FFT to produce line\nspectra for these signals. The logarithmic plots show steadily\nincreasing values as the peaks are approached from both sides, to such\nan extent that one of the targets in the plot for $|v_{5}|$ can hardly\nbe distinguished even though it is separated by several range bins\nfrom the large target. The broadening is caused by *side lobes* in the\nDFT. These are caused by an inherent clash between the properties of\nthe signal we analyzed and the signal produced by the inverse DFT.\n\n-->\n<p>Here are the signals used thus far in this example, windowed with a\nKaiser window with $\\beta=6.1$:</p>\n<pre><code class=\"language-python\">f, axes = plt.subplots(3, 1, sharex=True, figsize=(4.8, 2.8))\n\nt_ms = t * 1000  # Sample times in milli-second\n\nw = np.kaiser(N, 6.1)  # Kaiser window with beta = 6.1\n\nfor n, (signal, label) in enumerate([(v_single, r'$v_0 [V]$'),\n                                     (v_sim, r'$v_5 [V]$'),\n                                     (v_actual, r'$v_{\\mathrm{actual}} [V]$')]):\n    with plt.style.context('style/thinner.mplstyle'):\n        axes[n].plot(t_ms, w * signal)\n        axes[n].set_ylabel(label)\n        axes[n].grid()\n\naxes[2].set_xlim(0, t_ms[-1])\naxes[2].set_xlabel('Time [ms]');\n</code></pre>\n<!-- caption text=\"Windowed signals for: (a) single simulated target, (b) multiple simulated targets, (c) real targets\" -->\n<p>And the corresponding FFTs (or \"range traces\", in radar terms):</p>\n<pre><code class=\"language-python\">V_single_win = np.fft.fft(w * v_single)\nV_sim_win = np.fft.fft(w * v_sim)\nV_actual_win = np.fft.fft(w * v_actual)\n\nfig, (ax0, ax1,ax2) = plt.subplots(3, 1)\n\nwith plt.style.context('style/thinner.mplstyle'):\n    log_plot_normalized(rng, V_single_win[:N // 2],\n                        r\"$|V_{0,\\mathrm{win}}|$ [dB]\", ax0)\n    log_plot_normalized(rng, V_sim_win[:N // 2],\n                        r\"$|V_{5,\\mathrm{win}}|$ [dB]\", ax1)\n    log_plot_normalized(rng, V_actual_win[:N // 2],\n                        r\"$|V_\\mathrm{actual,win}|$ [dB]\", ax2)\n\nax0.set_xlim(0, 300)  # Change x limits for these plots so that\nax1.set_xlim(0, 300)  # we are better able to see the shape of the peaks.\n\nax1.annotate(\"New, previously unseen!\", (160, -35), xytext=(10, 15),\n             textcoords=\"offset points\", color='red', size='x-small',\n             arrowprops=dict(width=0.5, headwidth=3, headlength=4,\n                             fc='k', shrink=0.1));\n</code></pre>\n<!-- caption text=\"Range traces (spectrum) of windowed signals\" -->\n<p>Compare these with the earlier range traces. There is a dramatic\nlowering in side lobe level, but at a price: the peaks have changed in\nshape, widening and becoming less peaky, thus lowering the radar\nresolution, that is, the ability of the radar to distinguish between\ntwo closely space targets. The choice of window is a compromise\nbetween side lobe level and resolution. Even so, referring to the\ntrace for $V_\\mathrm{sim}$, windowing has dramatically increased our\nability to distinguish the small target from its large neighbor.</p>\n<p>In the real radar data range trace windowing has also reduced the side\nlobes. This is most visible in the depth of the notch between the two\ngroups of targets.</p>\n<h3>Radar Images</h3>\n<p>Knowing how to analyze a single trace, we can expand to looking at\nradar images.</p>\n<p>The data is produced by a radar with a parabolic reflector antenna. It\nproduces a highly directive round pencil beam with a $2^\\circ$\nspreading angle between half-power points. When directed with normal\nincidence at a plane, the radar will illuminate a spot of about $2$ meters in\ndiameter at a distance of 60 meters.\nOutside this spot, the power drops off quite rapidly, but strong\nechoes from outside the spot will nevertheless still be visible.</p>\n<p>By varying the pencil beam's azimuth (left-right position) and\nelevation (up-down position), we can sweep it across the target area\nof interest. When reflections are picked up, we can calculate the\ndistance to the reflector (the object hit by the radar signal).\nTogether with the current pencil beam azimuth and elevation, this\ndefines the reflector's position in 3D.</p>\n<p>A rock slope consists of thousands of reflectors. A range bin can be\nthought of as a large sphere with the radar at its center that\nintersects the slope along a ragged line. The scatterers on this line\nwill produce reflections in this range bin. The wavelength of the\nradar (distance the transmitted wave travels in one oscillation\nsecond) is about 30 mm. The reflections from scatterers separated by\nodd multiples of a quarter wavelength in range, about 7.5 mm, will\ntend to interfere destructively, while those from scatterers separated\nby multiples of a half wavelength will tend to interfere\nconstructively at the radar. The reflections combine to produce\napparent spots of strong reflections. This specific radar moves its\nantenna in order to scan small regions consisting of $20^\\circ$\nazimuth and $30^\\circ$ elevation bins scanned in steps of $0.5^\\circ$.</p>\n<p>We will now draw some contour plots of the resulting radar data.\nPlease refer to the diagram below to see how the different slices are\ntaken. A first slice at fixed range shows the strength of echoes\nagainst elevation and azimuth. Another two slices at fixed elevation\nand azimuth respectively shows the slope. The stepped construction of\nthe high wall in an opencast mine is visible in the azimuth plane.</p>\n<p><img src=\"../figures/axes_slices.png\"\n     alt=\"Diagram showing azimuth, elevation and range slices through data volume\"/></p>\n<pre><code class=\"language-python\">data = np.load('data/radar_scan_1.npz')\nscan = data['scan']\n\n# The signal amplitude ranges from -2.5V to +2.5V.  The 14-bit\n# analogue-to-digital converter in the radar gives out integers\n# between -8192 to 8192.  We convert back to voltage by multiplying by\n# $(2.5 / 8192)$.\n\nv = scan['samples'] * 2.5 / 8192\nwin = np.hanning(N + 1)[:-1]\n\n# Take FFT for each measurement\nV = np.fft.fft(v * win, axis=2)[::-1, :, :N // 2]\n\ncontours = np.arange(-40, 1, 2)\n\n# ignore MPL layout warnings\nimport warnings\nwarnings.filterwarnings('ignore', '.*Axes.*compatible.*tight_layout.*')\n\nf, axes = plt.subplots(2, 2, figsize=(4.8, 4.8), tight_layout=True)\n\nlabels = ('Range', 'Azimuth', 'Elevation')\n\ndef plot_slice(ax, radar_slice, title, xlabel, ylabel):\n    ax.contourf(dB(radar_slice), contours, cmap='magma_r')\n    ax.set_title(title)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    ax.set_facecolor(plt.cm.magma_r(-40))\n\nwith plt.style.context('style/thinner.mplstyle'):\n    plot_slice(axes[0, 0], V[:, :, 250], 'Range=250', 'Azimuth', 'Elevation')\n    plot_slice(axes[0, 1], V[:, 3, :], 'Azimuth=3', 'Range', 'Elevation')\n    plot_slice(axes[1, 0], V[6, :, :].T, 'Elevation=6', 'Azimuth', 'Range')\n    axes[1, 1].axis('off')\n</code></pre>\n<!-- caption text=\"Contour plots of range traces along various axes (see diagram)\" -->\n<h4>3D visualization</h4>\n<p>We can also visualize the volume in three dimensions.</p>\n<p>We first compute the argmax (the index of the maximum value) in the\nrange direction. This should give an indication of the range at which\nthe radar beam hit the rock slope. Each argmax index is converted to\na three-dimensional (elevation-azimuth-range) coordinate:</p>\n<pre><code class=\"language-python\">r = np.argmax(V, axis=2)\n\nel, az = np.meshgrid(*[np.arange(s) for s in r.shape], indexing='ij')\n\naxis_labels = ['Elevation', 'Azimuth', 'Range']\ncoords = np.column_stack((el.flat, az.flat, r.flat))\n</code></pre>\n<p>Taking these coordinates, we project them onto the plane (by dropping\nthe range coordinate), and perform a Delaunay tesselation. The\ntesselation returns a set of indices into our coordinates that define\ntriangles (or simplices). While the triangles are strictly speaking\ndefined on the projected coordinates, we use our original coordinates\nfor the reconstruction, thereby adding back the range component:</p>\n<pre><code class=\"language-python\">from scipy import spatial\n\nd = spatial.Delaunay(coords[:, :2])\nsimplexes = coords[d.vertices]\n</code></pre>\n<p>For display purposes, we swap the range axis to be the first:</p>\n<pre><code class=\"language-python\">coords = np.roll(coords, shift=-1, axis=1)\naxis_labels = np.roll(axis_labels, shift=-1)\n</code></pre>\n<p>Now, Matplotlib's <code>trisurf</code> can be used to visualize the result:</p>\n<pre><code class=\"language-python\"># This import initializes Matplotlib's 3D machinery\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Set up the 3D axis\nf, ax = plt.subplots(1, 1, figsize=(4.8, 4.8),\n                     subplot_kw=dict(projection='3d'))\n\nwith plt.style.context('style/thinner.mplstyle'):\n    ax.plot_trisurf(*coords.T, triangles=d.vertices, cmap='magma_r')\n\n    ax.set_xlabel(axis_labels[0])\n    ax.set_ylabel(axis_labels[1])\n    ax.set_zlabel(axis_labels[2], labelpad=-3)\n    ax.set_xticks([0, 5, 10, 15])\n\n# Adjust the camera position to match our diagram above\nax.view_init(azim=-50);\n</code></pre>\n<!-- caption text=\"3-D visualization of estimated rock slope position\" -->\n<h3>Further applications of the FFT</h3>\n<p>The examples above show just one of the uses of the FFT in\nradar. There are many others, such as movement (Doppler) measurement\nand target recognition. The fast Fourier transform is pervasive, and is\nseen anywhere from Magnetic Resonance Imaging (MRI) to statistics.\nWith the basic techniques that this chapter outlines in hand, you\nshould be well equipped to use it!</p>\n<h3>Further reading</h3>\n<p>On the Fourier transform:</p>\n<ul>\n<li>A. Papoulis, <em>The Fourier Integral and Its Applications</em>,</li>\n<li>McGraw-Hill, 1960.</li>\n<li>Ronald A. Bracewell, <em>The Fourier Transform and Its Applications</em>,\nMcGraw-Hill, 1986.</li>\n</ul>\n<p>On radar signal processing:</p>\n<ul>\n<li>Mark A. Richards, <em>Principles of Modern Radar: Basic Principles</em>,</li>\n<li>SciTech, 2010</li>\n<li>Mark A. Richards, <em>Fundamentals of Radar Signal Processing</em>,\nMcGraw-Hill, 2014.</li>\n</ul>\n<!-- exercise begin -->\n<p><strong>Exercise:</strong> The FFT is often used to speed up image convolution\n(convolution is the application of a moving filter mask). Convolve an\nimage with <code>np.ones((5, 5))</code>, using a) numpy's <code>np.convolve</code> and\nb) <code>np.fft.fft2</code>. Confirm that the results are identical.</p>\n<p>Hints:</p>\n<ul>\n<li>The convolution of <code>x</code> and <code>y</code> is equivalent to <code>ifft2(X * Y)</code>, where</li>\n<li><code>X</code> and <code>Y</code> are the FFTs of x and y respectively.</li>\n<li>In order to multiply <code>X</code> and <code>Y</code>, they have to be the same size.\nUse <code>np.pad</code> to extend <code>x</code> and <code>y</code> with zeros (toward the right and\nbottom) <em>before</em> taking their FFT.</li>\n<li>You may see some edge effects. These can be removed by increasing\nthe padding size, so that both <code>x</code> and <code>y</code> have dimensions\n<code>shape(x) + shape(y) - 1</code>.</li>\n</ul>\n<!-- solution begin -->\n<p><strong>Solution:</strong></p>\n<pre><code class=\"language-python\">from scipy import signal\n\nx = np.random.random((50, 50))\ny = np.ones((5, 5))\n\nL = x.shape[0] + y.shape[0] - 1\nPx = L - x.shape[0]\nPy = L - y.shape[0]\n\nxx = np.pad(x, ((0, Px), (0, Px)), mode='constant')\nyy = np.pad(y, ((0, Py), (0, Py)), mode='constant')\n\nzz = np.fft.ifft2(np.fft.fft2(xx) * np.fft.fft2(yy)).real\nprint('Resulting shape:', zz.shape, ' &#x3C;-- Why?')\n\nz = signal.convolve2d(x, y)\n\nprint('Results are equal?', np.allclose(zz, z))\n</code></pre>\n<!-- solution end -->\n<!-- exercise end -->\n<div class=\"footnotes\">\n<hr>\n<ol>\n<li id=\"fn-discrete\">\n<p>The discrete Fourier transform operates on sampled data,\nin contrast to the standard Fourier transform which is\ndefined for continuous functions.</p>\n<a href=\"#fnref-discrete\" class=\"footnote-backref\">↩</a>\n</li>\n<li id=\"fn-complex\">\n<p>The Fourier transform essentially tells us how to combine\na set of sinusoids of varying frequency to form the input\nsignal. The spectrum consists of complex numbers—one for\neach sinusoid. A complex number encodes two things: a\nmagnitude and an angle. The magnitude is the strength of\nthe sinusoid in the signal, and the angle how much it is\nshifted in time. At this point, we only care about the\nmagnitude, which we calculate using <code>np.abs</code>.</p>\n<a href=\"#fnref-complex\" class=\"footnote-backref\">↩</a>\n</li>\n<li id=\"fn-time\">\n<p>For more on techniques for calculating both (approximate) frequencies\nand time of occurrence, read up on wavelet analysis.</p>\n<a href=\"#fnref-time\" class=\"footnote-backref\">↩</a>\n</li>\n<li id=\"fn-scaling\">\n<p>SciPy goes to some effort to preserve the energy in the\nspectrum. Therefore, when taking only half the components\n(for N even), it multiplies the remaining components,\napart from the first and last components, by two (those\ntwo components are \"shared\" by the two halves of the\nspectrum). It also normalizes the window by dividing it\nby its sum.</p>\n<a href=\"#fnref-scaling\" class=\"footnote-backref\">↩</a>\n</li>\n<li id=\"fn-periodic\">\n<p>The period can, in fact, also be infinite! The general\ncontinuous Fourier transform provides for this\npossibility. Discrete Fourier transforms are generally\ndefined over a finite interval, and this is implicitly\nthe period of the time domain function that is\ntransformed. In other words, if you do the inverse\ndiscrete Fourier transform, you <em>always</em> get a periodic\nsignal out.</p>\n<a href=\"#fnref-periodic\" class=\"footnote-backref\">↩</a>\n</li>\n<li id=\"fn-big_o\">\n<p>In computer science, the computational cost of an algorithm\nis often expressed in \"Big O\" notation. The notation gives\nus an indication of how an algorithm's execution time scales\nwith an increasing number of elements. If an algorithm is $\\mathcal{O}(N)$,\nit means its execution time increases linearly with\nthe number of input elements (for example, searching for a\ngiven value in an unsorted list is $\\mathcal{O}\\left(N\\right)$). Bubble sort is\nan example of an $O\\left(N^2\\right)$ algorithm; the exact number of\noperations performed may, hypothetically, be $N + \\frac{1}{2} N^2$,\nmeaning that the computational cost grows quadratically with\nthe number of input elements.</p>\n<a href=\"#fnref-big_o\" class=\"footnote-backref\">↩</a>\n</li>\n<li id=\"fn-fast\">\n<p>While ideally we don't want to reimplement existing\nalgorithms, sometimes it becomes necessary in order to obtain\nthe best execution speeds possible, and tools\nlike <a href=\"http://cython.org\">Cython</a>—which compiles Python to\nC—and <a href=\"http://numba.pydata.org\">Numba</a>—which does\njust-in-time compilation of Python code—make life a lot\neasier (and faster!). If you are able to use GPL-licenced\nsoftware, you may consider\nusing <a href=\"https://github.com/hgomersall/pyFFTW\">PyFFTW</a> for\nfaster FFTs.</p>\n<a href=\"#fnref-fast\" class=\"footnote-backref\">↩</a>\n</li>\n<li id=\"fn-odd_n\">\n<p>We leave it as an exercise for the reader to picture the\nsituation for $N$ odd. In this chapter, all examples use\neven-order DFTs.</p>\n<a href=\"#fnref-odd_n\" class=\"footnote-backref\">↩</a>\n</li>\n<li id=\"fn-choosing_a_window\">\n<p>The classical windowing functions include Hann,\nHamming, and Blackman. They differ in their\nsidelobe levels and in the broadening of the\nmain lobe (in the Fourier domain). A modern and\nflexible window function that is close to\noptimal for most applications is the Kaiser\nwindow—a good approximation to the optimal\nprolate spheroid window, which concentrates the\nmost energy into the main lobe. The Kaiser\nwindow can be tuned to suit the particular\napplication, as illustrated in the main text, by\nadjusting the parameter $\\beta$.</p>\n<a href=\"#fnref-choosing_a_window\" class=\"footnote-backref\">↩</a>\n</li>\n</ol>\n</div>"}